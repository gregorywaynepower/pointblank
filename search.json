[
  {
    "objectID": "get-started/index.html",
    "href": "get-started/index.html",
    "title": "Intro",
    "section": "",
    "text": "The pointblank library is all about assessing the state of data quality in a table. You provide the validation rules and the library will dutifully interrogate the data and provide useful reporting. We can use different types of tables like Polars and Pandas DataFrames, Parquet files, or a selection of DB tables. Let’s walk through what table validation looks like in pointblank!"
  },
  {
    "objectID": "get-started/index.html#a-simple-validation-table",
    "href": "get-started/index.html#a-simple-validation-table",
    "title": "Intro",
    "section": "A Simple Validation Table",
    "text": "A Simple Validation Table\nThis is a validation table that is produced from a validation of a Polars DataFrame:\n\n\nCode\nimport pointblank as pb\n\nvalidation_1 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\n\nvalidation_1\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:50:06Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n        \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_between()\n        \n    d\n    [0, 5000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:50:06 UTC&lt; 1 s2025-01-02 04:50:06 UTC\n  \n\n\n\n\n\n\n        \n\n\nEach row in this reporting table constitutes a single validation step. Roughly, the left-hand side outlines the validation rules and the right-hand side provides the results of each validation step. While simple in principle, there’s a lot of useful information packed into this validation table.\nHere’s a diagram that describes a few of the important parts of the validation table:\n\nThere are three important sections of this table,\n\nvalidation steps: each step is a distinct test on the table focused on a certain part of the table (here, the different columns)\nvalidation rules: the validation type is provided here along with key constraints\nvalidation results: post-interrogation results are provided here, with a breakdown of test units (total, passing, failing), threshold states, etc.\n\nThe intent is to provide the key information in one place, and have it be interpretable by a broad audience."
  },
  {
    "objectID": "get-started/index.html#example-code-step-by-step",
    "href": "get-started/index.html#example-code-step-by-step",
    "title": "Intro",
    "section": "Example Code, Step-by-Step",
    "text": "Example Code, Step-by-Step\nHere’s the code that performs the validation on the Polars table.\n\nimport pointblank as pb\n\nvalidation_2 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:50:06Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n        \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_between()\n        \n    d\n    [0, 5000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:50:06 UTC&lt; 1 s2025-01-02 04:50:06 UTC\n  \n\n\n\n\n\n\n        \n\n\nNote these three key pieces in the code:\n\nthe Validate(data=...) argument takes a DataFrame that you want to validate\nthe methods starting with col_* specify validation steps that run on specific columns\nthe interrogate() method executes the validation plan on the table\n\nThat’s data validation with pointblank in a nutshell! In the next section we’ll go a bit further by introducing a means to gauge data quality with failure thresholds."
  },
  {
    "objectID": "get-started/index.html#understanding-test-units",
    "href": "get-started/index.html#understanding-test-units",
    "title": "Intro",
    "section": "Understanding Test Units",
    "text": "Understanding Test Units\nEach validation step will execute a validation test. For example, col_vals_lt() tests that each value in a column is less than a specified number. One important piece that’s reported is the number of test units that pass or fail.\nTest units are dependent on the test being run. The col_vals_* tests each value in a column, so each value will be a test unit.\nThis matters because you can set thresholds that signal WARN, STOP, and NOTIFY states based the proportion or number of failing test units.\nHere’s a simple example that uses a single col_vals_lt() step along with thresholds.\n\nvalidation_3 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(columns=\"a\", value=7, thresholds=(2, 4))\n    .interrogate()\n)\n\nvalidation_3\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:50:06Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #FFBF00\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-01-02 04:50:06 UTC&lt; 1 s2025-01-02 04:50:06 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe code uses thresholds=(2, 4) to set a WARN threshold of 2 and a STOP threshold of 4. Notice these pieces in the validation table:\n\nThe FAIL column shows that 2 tests units have failed\nThe W column (short for WARN) shows a filled yellow circle indicating it’s reached threshold\nThe S column (short for STOP) shows an open red circle indicating it’s below threshold\n\nThe one final threshold, N (NOTIFY), wasn’t set so appears on the validation table as a dash.\nThresholds let you take action at different levels of severity. The next section discusses setting and acting on thresholds in detail."
  },
  {
    "objectID": "get-started/index.html#using-threshold-levels",
    "href": "get-started/index.html#using-threshold-levels",
    "title": "Intro",
    "section": "Using Threshold Levels",
    "text": "Using Threshold Levels\nThresholds enable you to signal failure at different severity levels. In the near future, thresholds will be able to trigger custom actions. For example, when testing a column for NULLs with col_vals_not_null() you might want to warn on any NULLs and stop where there are 20% NULLs in the column.\n\nvalidation_4 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_not_null(columns=\"c\", thresholds=(1, 0.2))\n    .interrogate()\n)\n\nvalidation_4\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:50:06Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #FFBF00\n    1\n    \n        \n        \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_null()\n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-01-02 04:50:06 UTC&lt; 1 s2025-01-02 04:50:06 UTC\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the thresholds= argument in the cols_vals_not_null() step was used, but we can also set thresholds globally by using Validate(thresholds=...).\nFor more on thresholds, see the Thresholds article."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pointblank",
    "section": "",
    "text": "Find out if your data is what you think it is\nPointblank is a table validation and testing library for Python. It helps you ensure that your tabular data meets certain expectations and constraints and it can present the results in a beautiful and useful tabular reporting framework."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "pointblank",
    "section": "Getting Started",
    "text": "Getting Started\nLet’s take a Polars DataFrame and validate it against a set of constraints. We do that using the Validate class and its collection of validation methods:\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\")) # Use Validate() to start\n    .col_vals_gt(columns=\"d\", value=100)       # STEP 1 |\n    .col_vals_le(columns=\"c\", value=5)         # STEP 2 | &lt;-- Building a validation plan\n    .col_exists(columns=[\"date\", \"date_time\"]) # STEP 3 |\n    .interrogate() # This will execute all validation steps and collect intel\n)\n\nvalidation\n\n\n\nThe rows in the validation table correspond to each of the validation steps. One of the key concepts is that validation steps can be broken down into atomic test cases (test units) and each of these test units is given either of pass/fail status based on the validation constraints. You’ll see these tallied up in the reporting table (in the UNITS, PASS, and FAIL columns).\nTabular reporting is just one way to see the results. You can also obtain fine-grained results of the interrogation as JSON output or through methods that get key metrics. You can also utilize the validation results to perform filtering of the input table based on row-level pass/fail status (via the get_sundered_data() method).\nOn the input side, we can use the following types of tables:\n\nPolars DataFrame\nPandas DataFrame\nDuckDB table\nMySQL table\nPostgreSQL table\nSQLite table\nParquet\n\nTo make this all work seamlessly, we use Narwhals to work with Polars and Pandas DataFrames. We also integrate with Ibis to enable the use of DuckDB, MySQL, PostgreSQL, SQLite, and Parquet. In doing all of this, we can provide an ergonomic and consistent API for validating tabular data from various sources."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "pointblank",
    "section": "Features",
    "text": "Features\nHere’s a short list of what we think makes pointblank a great tool for data validation:\n\nDeclarative Syntax: Define your data validation rules using a declarative syntax\nFlexible: We support tables from Polars, Pandas, Duckdb, MySQL, PostgreSQL, SQLite, and Parquet\nBeautiful Reports: Generate beautiful HTML reports of your data validation results\nFunctional Output: Get JSON output of your data validation results for further processing\nData Testing: Write tests for your data and use them in your notebooks or testing framework\nEasy to Use: Get started quickly with a simple API and clear documentation"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "pointblank",
    "section": "Installation",
    "text": "Installation\nYou can install pointblank using pip:\npip install pointblank\nIf you encounter a bug, have usage questions, or want to share ideas to make this package better, please feel free to file an issue."
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "pointblank",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease note that the pointblank project is released with a contributor code of conduct.By participating in this project you agree to abide by its terms."
  },
  {
    "objectID": "index.html#contributing-to-pointblank",
    "href": "index.html#contributing-to-pointblank",
    "title": "pointblank",
    "section": "Contributing to pointblank",
    "text": "Contributing to pointblank\nThere are many ways to contribute to the ongoing development of pointblank. Some contributions can be simple (like fixing typos, improving documentation, filing issues for feature requests or problems, etc.) and others might take more time and care (like answering questions and submitting PRs with code changes). Just know that anything you can do to help would be very much appreciated!\nPlease read over the contributing guidelines for information on how to get started."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "pointblank",
    "section": "📄 License",
    "text": "📄 License\nPointblank is licensed under the MIT license."
  },
  {
    "objectID": "index.html#governance",
    "href": "index.html#governance",
    "title": "pointblank",
    "section": "🏛️ Governance",
    "text": "🏛️ Governance\nThis project is primarily maintained by Rich Iannone. Other authors may occasionally assist with some of these duties."
  },
  {
    "objectID": "reference/Validate.stop.html",
    "href": "reference/Validate.stop.html",
    "title": "Validate.stop",
    "section": "",
    "text": "Validate.stop(i=None, scalar=False)\nProvides a dictionary of the stopping status for each validation step.\nThe stopping status (stop) for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the stopping level. Otherwise, the status is False.\nThe ascribed name of stop is semantic and does not imply that the validation process is halted, it is simply a status indicator that could be used to trigger a stoppage of the validation process. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the stopping status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.stop.html#parameters",
    "href": "reference/Validate.stop.html#parameters",
    "title": "Validate.stop",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the stopping status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.stop.html#returns",
    "href": "reference/Validate.stop.html#returns",
    "title": "Validate.stop",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the stopping status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.stop.html#examples",
    "href": "reference/Validate.stop.html#examples",
    "title": "Validate.stop",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have some failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe warn threshold is 2 failing test units\nthe stop threshold is 4 failing test units\nthe notify threshold is 5 failing test units\n\nAfter interrogation, the stop() method is used to determine the stop status for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [3, 4, 9, 7, 2, 3, 8],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.stop()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the stop status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the stop level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the stop level.\nWe can also visually inspect the stop status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:49:56PolarsWARN2STOP4NOTIFY5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #CF142B\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    30.43\n    40.57\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:49:56 UTC&lt; 1 s2025-01-02 04:49:56 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there are filled yellow and red circles in the first step (far right side, in the W and S columns) indicating that the warn and stop thresholds were met. The other steps have empty yellow and red circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the stop status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.stop(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had the stop threshold met."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html",
    "href": "reference/Validate.get_data_extracts.html",
    "title": "Validate.get_data_extracts",
    "section": "",
    "text": "Validate.get_data_extracts(i=None, frame=False)\nGet the rows that failed for each validation step.\nAfter the interrogate() method has been called, the get_data_extracts() method can be used to extract the rows that failed in each row-based validation step (e.g., col_vals_gt(), etc.). The method returns a dictionary of tables containing the rows that failed in every row-based validation function. If frame=True and i= is a scalar, the value is conveniently returned as a table (forgoing the dictionary structure)."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#parameters",
    "href": "reference/Validate.get_data_extracts.html#parameters",
    "title": "Validate.get_data_extracts",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the failed rows are obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nframe : bool = False\n\nIf True and i= is a scalar, return the value as a DataFrame instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#returns",
    "href": "reference/Validate.get_data_extracts.html#returns",
    "title": "Validate.get_data_extracts",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, FrameT | None] | FrameT | None\n\nA dictionary of tables containing the rows that failed in every row-based validation step or a DataFrame."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#validation-methods-that-are-row-based",
    "href": "reference/Validate.get_data_extracts.html#validation-methods-that-are-row-based",
    "title": "Validate.get_data_extracts",
    "section": "Validation Methods that are Row-Based",
    "text": "Validation Methods that are Row-Based\nThe following validation methods are row-based and will have rows extracted when there are failing test units.\n\ncol_vals_gt()\ncol_vals_ge()\ncol_vals_lt()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\n\nAn extracted row means that a test unit failed for that row in the validation step. The extracted rows are a subset of the original table and are useful for further analysis or for understanding the nature of the failing test units."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#examples",
    "href": "reference/Validate.get_data_extracts.html#examples",
    "title": "Validate.get_data_extracts",
    "section": "Examples",
    "text": "Examples\nLet’s perform a series of validation steps on a Polars DataFrame. We’ll use the col_vals_gt() in the first step, col_vals_lt() in the second step, and col_vals_ge() in the third step. The interrogate() method executes the validation; then, we can extract the rows that failed for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 3, 6, 1],\n        \"b\": [1, 2, 1, 5, 2, 6],\n        \"c\": [3, 7, 2, 6, 3, 1],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=4)\n    .col_vals_lt(columns=\"c\", value=5)\n    .col_vals_ge(columns=\"b\", value=1)\n    .interrogate()\n)\n\nvalidation.get_data_extracts()\n\n{1: shape: (2, 3)\n ┌─────┬─────┬─────┐\n │ a   ┆ b   ┆ c   │\n │ --- ┆ --- ┆ --- │\n │ i64 ┆ i64 ┆ i64 │\n ╞═════╪═════╪═════╡\n │ 3   ┆ 5   ┆ 6   │\n │ 1   ┆ 6   ┆ 1   │\n └─────┴─────┴─────┘,\n 2: shape: (2, 3)\n ┌─────┬─────┬─────┐\n │ a   ┆ b   ┆ c   │\n │ --- ┆ --- ┆ --- │\n │ i64 ┆ i64 ┆ i64 │\n ╞═════╪═════╪═════╡\n │ 6   ┆ 2   ┆ 7   │\n │ 3   ┆ 5   ┆ 6   │\n └─────┴─────┴─────┘,\n 3: shape: (0, 3)\n ┌─────┬─────┬─────┐\n │ a   ┆ b   ┆ c   │\n │ --- ┆ --- ┆ --- │\n │ i64 ┆ i64 ┆ i64 │\n ╞═════╪═════╪═════╡\n └─────┴─────┴─────┘}\n\n\nThe get_data_extracts() method returns a dictionary of tables, where each table contains a subset of rows from the table. These are the rows that failed for each validation step.\nIn the first step, the col_vals_gt() method was used to check if the values in column a were greater than 4. The extracted table shows the rows where this condition was not met; look at the a column: all values are less than 4.\nIn the second step, the col_vals_lt() method was used to check if the values in column c were less than 5. In the extracted two-row table, we see that the values in column c are greater than 5.\nThe third step (col_vals_ge()) checked if the values in column b were greater than or equal to 1. There were no failing test units, so the extracted table is empty (i.e., has columns but no rows).\nThe i= argument can be used to narrow down the extraction to one or more steps. For example, to extract the rows that failed in the first step only:\n\nvalidation.get_data_extracts(i=1)\n\n{1: shape: (2, 3)\n ┌─────┬─────┬─────┐\n │ a   ┆ b   ┆ c   │\n │ --- ┆ --- ┆ --- │\n │ i64 ┆ i64 ┆ i64 │\n ╞═════╪═════╪═════╡\n │ 3   ┆ 5   ┆ 6   │\n │ 1   ┆ 6   ┆ 1   │\n └─────┴─────┴─────┘}\n\n\nNote that the first validation step is indexed at 1 (not 0). This 1-based indexing is in place here to match the step numbers reported in the validation table. What we get back is still a dictionary, but it only contains one table (the one for the first step).\nIf you want to get the extracted table as a DataFrame, set frame=True and provide a scalar value for i. For example, to get the extracted table for the second step as a DataFrame:\n\nvalidation.get_data_extracts(i=2, frame=True)\n\n\nshape: (2, 3)abci64i64i64627356\n\n\nThe extracted table is now a DataFrame, which can serve as a more convenient format for further analysis or visualization."
  },
  {
    "objectID": "reference/Validate.warn.html",
    "href": "reference/Validate.warn.html",
    "title": "Validate.warn",
    "section": "",
    "text": "Validate.warn(i=None, scalar=False)\nProvides a dictionary of the warning status for each validation step.\nThe warning status (warn) for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the warning level. Otherwise, the status is False.\nThe ascribed name of warn is semantic and does not imply that a warning message is generated, it is simply a status indicator that could be used to trigger a warning message. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the warning status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.warn.html#parameters",
    "href": "reference/Validate.warn.html#parameters",
    "title": "Validate.warn",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the warning status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.warn.html#returns",
    "href": "reference/Validate.warn.html#returns",
    "title": "Validate.warn",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the warning status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.warn.html#examples",
    "href": "reference/Validate.warn.html#examples",
    "title": "Validate.warn",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have some failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe warn threshold is 2 failing test units\nthe stop threshold is 4 failing test units\nthe notify threshold is 5 failing test units\n\nAfter interrogation, the warn() method is used to determine the warn status for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.warn()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the warn status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the warn level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the warn level.\nWe can also visually inspect the warn status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:49:48PolarsWARN2STOP4NOTIFY5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #FFBF00\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    50.71\n    20.29\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:49:48 UTC&lt; 1 s2025-01-02 04:49:48 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there’s a filled yellow circle in the first step (far right side, in the W column) indicating that the warn threshold was met. The other steps have empty yellow circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the warn status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.warn(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had the warn threshold met."
  },
  {
    "objectID": "reference/Validate.f_passed.html",
    "href": "reference/Validate.f_passed.html",
    "title": "Validate.f_passed",
    "section": "",
    "text": "Validate.f_passed(i=None, scalar=False)\nProvides a dictionary of the fraction of test units that passed for each validation step.\nA measure of the fraction of test units that passed is provided by the f_passed attribute. This is the fraction of test units that passed the validation step over the total number of test units. Given this is a fractional value, it will always be in the range of 0 to 1.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThis method provides a dictionary of the fraction of passing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the f_failed() method (i.e., 1 - f_failed())."
  },
  {
    "objectID": "reference/Validate.f_passed.html#parameters",
    "href": "reference/Validate.f_passed.html#parameters",
    "title": "Validate.f_passed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the fraction of passing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.f_passed.html#returns",
    "href": "reference/Validate.f_passed.html#returns",
    "title": "Validate.f_passed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, float] | float\n\nA dictionary of the fraction of passing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.f_passed.html#examples",
    "href": "reference/Validate.f_passed.html#examples",
    "title": "Validate.f_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, all having some failing test units. After interrogation, the f_passed() method is used to determine the fraction of passing test units for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\", \"d\", \"c\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.f_passed()\n\n{1: 0.7142857142857143, 2: 0.5714285714285714, 3: 0.5714285714285714}\n\n\nThe returned dictionary shows the fraction of passing test units for each validation step. The values are all less than 1 since there were failing test units in each step.\nIf we wanted to check the fraction of passing test units for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.f_passed(i=1)\n\n{1: 0.7142857142857143}\n\n\nThe returned value is the proportion of passing test units for the first validation step (5 passing test units out of 7 total test units)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html",
    "href": "reference/Validate.col_vals_between.html",
    "title": "Validate.col_vals_between",
    "section": "",
    "text": "Validate.col_vals_between(\n    columns,\n    left,\n    right,\n    inclusive=(True, True),\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nDo column data lie between two specified values or data in other columns?\nThe col_vals_between() validation method checks whether column values in a table fall within a range. The range is specified with three arguments: left=, right=, and inclusive=. The left= and right= values specify the lower and upper bounds. These bounds can be specified as literal values or as column names provided within col(). The validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#parameters",
    "href": "reference/Validate.col_vals_between.html#parameters",
    "title": "Validate.col_vals_between",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nleft : float | int | Column\n\nThe lower bound of the range. Can be a single numeric value or a column name given in col().\n\nright : float | int | Column\n\nThe upper bound of the range. Can be a single numeric value or a column name given in col().\n\ninclusive : tuple[bool, bool] = (True, True)\n\nA tuple of two boolean values indicating whether the comparison should be inclusive. The position of the boolean values correspond to the left= and right= values, respectively. By default, both values are True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#returns",
    "href": "reference/Validate.col_vals_between.html#returns",
    "title": "Validate.col_vals_between",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#examples",
    "href": "reference/Validate.col_vals_between.html#examples",
    "title": "Validate.col_vals_between",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [2, 3, 2, 4, 3, 4],\n        \"b\": [5, 6, 1, 6, 8, 5],\n        \"c\": [9, 8, 8, 7, 7, 8],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64259368218467387458\n\n\nLet’s validate that values in column a are all between the fixed boundary values of 1 and 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_between(columns=\"a\", left=1, right=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_between()\n        \n    a\n    [1, 5]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_between(). All test units passed, and there are no failing test units.\nAside from checking a column against two literal values representing the lower and upper bounds, we can also provide column names to the left= and/or right= arguments (by using the helper function col()). In this way, we can perform three additional comparison types:\n\nleft=column, right=column\nleft=literal, right=column\nleft=column, right=literal\n\nFor the next example, we’ll use col_vals_between() to check whether the values in column b are between than corresponding values in columns a (lower bound) and c (upper bound).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_between(columns=\"b\", left=pb.col(\"a\"), right=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_between()\n        \n    b\n    [a, c]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 2: b is 1 but the bounds are 2 (a) and 8 (c).\nRow 4: b is 8 but the bounds are 3 (a) and 7 (c)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html",
    "href": "reference/Validate.col_vals_not_null.html",
    "title": "Validate.col_vals_not_null",
    "section": "",
    "text": "Validate.col_vals_not_null(columns, pre=None, thresholds=None, active=True)\nValidate whether values in a column are not NULL.\nThe col_vals_not_null() validation method checks whether column values in a table are not NULL. This validation will operate over the number of test units that is equal to the number of rows in the table."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#parameters",
    "href": "reference/Validate.col_vals_not_null.html#parameters",
    "title": "Validate.col_vals_not_null",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#returns",
    "href": "reference/Validate.col_vals_not_null.html#returns",
    "title": "Validate.col_vals_not_null",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#examples",
    "href": "reference/Validate.col_vals_not_null.html#examples",
    "title": "Validate.col_vals_not_null",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [4, 7, 2, 8],\n        \"b\": [5, None, 1, None],\n    }\n)\n\ntbl\n\n\nshape: (4, 2)abi64i64457null218null\n\n\nLet’s validate that none of the values in column a are Null values. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_null(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_null()\n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_not_null(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_null(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_null()\n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the two Null values in column b."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html",
    "href": "reference/Validate.col_vals_lt.html",
    "title": "Validate.col_vals_lt",
    "section": "",
    "text": "Validate.col_vals_lt(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data less than a fixed value or data in another column?\nThe col_vals_lt() validation method checks whether column values in a table are less than a specified value= (the exact comparison used in this function is col_val &lt; value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#parameters",
    "href": "reference/Validate.col_vals_lt.html#parameters",
    "title": "Validate.col_vals_lt",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#returns",
    "href": "reference/Validate.col_vals_lt.html#returns",
    "title": "Validate.col_vals_lt",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#examples",
    "href": "reference/Validate.col_vals_lt.html#examples",
    "title": "Validate.col_vals_lt",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [1, 2, 1, 2, 2, 2],\n        \"c\": [2, 1, 1, 4, 3, 4],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64512621511924723524\n\n\nLet’s validate that values in column a are all less than the value of 10. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=\"a\", value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_lt(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_lt() to check whether the values in column b are less than values in column c.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=\"b\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    b\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 1: b is 2 and c is 1.\nRow 2: b is 1 and c is 1."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html",
    "href": "reference/Validate.col_vals_regex.html",
    "title": "Validate.col_vals_regex",
    "section": "",
    "text": "Validate.col_vals_regex(\n    columns,\n    pattern,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nValidate whether column values match a regular expression pattern.\nThe col_vals_regex() validation method checks whether column values in a table correspond to a pattern= matching expression. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#parameters",
    "href": "reference/Validate.col_vals_regex.html#parameters",
    "title": "Validate.col_vals_regex",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\npattern : str\n\nA regular expression pattern to compare against.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#returns",
    "href": "reference/Validate.col_vals_regex.html#returns",
    "title": "Validate.col_vals_regex",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#examples",
    "href": "reference/Validate.col_vals_regex.html#examples",
    "title": "Validate.col_vals_regex",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two string columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"rb-0343\", \"ra-0232\", \"ry-0954\", \"rc-1343\"],\n        \"b\": [\"ra-0628\", \"ra-583\", \"rya-0826\", \"rb-0735\"],\n    }\n)\n\ntbl\n\n\nshape: (4, 2)abstrstr\"rb-0343\"\"ra-0628\"\"ra-0232\"\"ra-583\"\"ry-0954\"\"rya-0826\"\"rc-1343\"\"rb-0735\"\n\n\nLet’s validate that all of the values in column a match a particular regex pattern. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_regex(columns=\"a\", pattern=r\"r[a-z]-\\d{4}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    a\n    r[a-z]-\\d{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_regex(). All test units passed, and there are no failing test units.\nNow, let’s use the same regex for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_regex(columns=\"b\", pattern=r\"r[a-z]-\\d{4}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    b\n    r[a-z]-\\d{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the string values of rows 1 and 2 in column b."
  },
  {
    "objectID": "reference/Validate.get_json_report.html",
    "href": "reference/Validate.get_json_report.html",
    "title": "Validate.get_json_report",
    "section": "",
    "text": "Validate.get_json_report(use_fields=None, exclude_fields=None)\nGet a report of the validation results as a JSON-formatted string.\n\n\n\nuse_fields : list[str] | None = None\n\nA list of fields to include in the report. If None, all fields are included.\n\nexclude_fields : list[str] | None = None\n\nA list of fields to exclude from the report. If None, no fields are excluded.\n\n\n\n\n\n\n : str\n\nA JSON-formatted string representing the validation report."
  },
  {
    "objectID": "reference/Validate.get_json_report.html#parameters",
    "href": "reference/Validate.get_json_report.html#parameters",
    "title": "Validate.get_json_report",
    "section": "",
    "text": "use_fields : list[str] | None = None\n\nA list of fields to include in the report. If None, all fields are included.\n\nexclude_fields : list[str] | None = None\n\nA list of fields to exclude from the report. If None, no fields are excluded."
  },
  {
    "objectID": "reference/Validate.get_json_report.html#returns",
    "href": "reference/Validate.get_json_report.html#returns",
    "title": "Validate.get_json_report",
    "section": "",
    "text": ": str\n\nA JSON-formatted string representing the validation report."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html",
    "href": "reference/Validate.col_vals_not_in_set.html",
    "title": "Validate.col_vals_not_in_set",
    "section": "",
    "text": "Validate.col_vals_not_in_set(\n    columns,\n    set,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nValidate whether column values are not in a set of values.\nThe col_vals_not_in_set() validation method checks whether column values in a table are not part of a specified set= of values. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#parameters",
    "href": "reference/Validate.col_vals_not_in_set.html#parameters",
    "title": "Validate.col_vals_not_in_set",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nset : list[float | int]\n\nA list of values to compare against.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False"
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#returns",
    "href": "reference/Validate.col_vals_not_in_set.html#returns",
    "title": "Validate.col_vals_not_in_set",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#examples",
    "href": "reference/Validate.col_vals_not_in_set.html#examples",
    "title": "Validate.col_vals_not_in_set",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 8, 1, 9, 1, 7],\n        \"b\": [1, 8, 2, 6, 9, 1],\n    }\n)\n\ntbl\n\n\nshape: (6, 2)abi64i64718812961971\n\n\nLet’s validate that none of the values in column a are in the set of [2, 3, 4, 5, 6]. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_in_set(columns=\"a\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_in_set()\n        \n    a\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_not_in_set(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_in_set(columns=\"b\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_in_set()\n        \n    b\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the column b values of 2 and 6, both of which are in the set of [2, 3, 4, 5, 6]."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "When peforming data validation, you’ll need the Validate class to get the process started. It’s given the target table and you can optionally provide some metadata and/or failure thresholds (using the Thresholds class or through shorthands for this task). The Validate class has numerous methods for defining validation steps and for obtaining post-interrogation metrics and data.\n\n\n\nValidate\nWorkflow for defining a set of validations on a table and interrogating for results.\n\n\nThresholds\nDefinition of threshold values.\n\n\nSchema\nDefinition of a schema object.\n\n\n\n\n\n\nValidation steps can be thought of as sequential validations on the target data. We call Validate’s validation methods to build up a validation plan: a collection of steps that, in the aggregate, provides good validation coverage.\n\n\n\nValidate.col_vals_gt\nAre column data greater than a fixed value or data in another column?\n\n\nValidate.col_vals_lt\nAre column data less than a fixed value or data in another column?\n\n\nValidate.col_vals_ge\nAre column data greater than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_le\nAre column data less than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_eq\nAre column data equal to a fixed value or data in another column?\n\n\nValidate.col_vals_ne\nAre column data not equal to a fixed value or data in another column?\n\n\nValidate.col_vals_between\nDo column data lie between two specified values or data in other columns?\n\n\nValidate.col_vals_outside\nDo column data lie outside of two specified values or data in other columns?\n\n\nValidate.col_vals_in_set\nValidate whether column values are in a set of values.\n\n\nValidate.col_vals_not_in_set\nValidate whether column values are not in a set of values.\n\n\nValidate.col_vals_null\nValidate whether values in a column are NULL.\n\n\nValidate.col_vals_not_null\nValidate whether values in a column are not NULL.\n\n\nValidate.col_vals_regex\nValidate whether column values match a regular expression pattern.\n\n\nValidate.col_exists\nValidate whether one or more columns exist in the table.\n\n\nValidate.rows_distinct\nValidate whether rows in the table are distinct.\n\n\nValidate.col_schema_match\nDo columns in the table (and their types) match a predefined schema?\n\n\ncol\nHelper function for referencing a column in the input table.\n\n\n\n\n\n\nThe validation plan is put into action when interrogate() is called. The workflow for performing a comprehensive validation is then: (1) Validate(), (2) , (3) interrogate(). After interrogation of the data, we can view a validation table (by printing the object or using get_tabular_report()), extract key metrics, or split the data based on the validation results (with get_sundered_data()).\n\n\n\nValidate.interrogate\nExecute each validation step against the table and store the results.\n\n\nValidate.get_data_extracts\nGet the rows that failed for each validation step.\n\n\nValidate.get_json_report\nGet a report of the validation results as a JSON-formatted string.\n\n\nValidate.get_tabular_report\nValidation report as a GT table.\n\n\nValidate.get_sundered_data\nGet the data that passed or failed the validation steps.\n\n\nValidate.all_passed\nDetermine if every validation step passed perfectly, with no failing test units.\n\n\nValidate.n\nProvides a dictionary of the number of test units for each validation step.\n\n\nValidate.n_passed\nProvides a dictionary of the number of test units that passed for each validation step.\n\n\nValidate.n_failed\nProvides a dictionary of the number of test units that failed for each validation step.\n\n\nValidate.f_passed\nProvides a dictionary of the fraction of test units that passed for each validation step.\n\n\nValidate.f_failed\nProvides a dictionary of the fraction of test units that failed for each validation step.\n\n\nValidate.warn\nProvides a dictionary of the warning status for each validation step.\n\n\nValidate.stop\nProvides a dictionary of the stopping status for each validation step.\n\n\nValidate.notify\nProvides a dictionary of the notification status for each validation step.\n\n\n\n\n\n\nThe utilities group contain functions that are helpful for the validation process. We can load datasets with load_dataset() and set global configuration parameters with config().\n\n\n\nload_dataset\nLoad a dataset hosted in the library as specified DataFrame type.\n\n\nconfig\nConfiguration settings for the pointblank library."
  },
  {
    "objectID": "reference/index.html#validate",
    "href": "reference/index.html#validate",
    "title": "API Reference",
    "section": "",
    "text": "When peforming data validation, you’ll need the Validate class to get the process started. It’s given the target table and you can optionally provide some metadata and/or failure thresholds (using the Thresholds class or through shorthands for this task). The Validate class has numerous methods for defining validation steps and for obtaining post-interrogation metrics and data.\n\n\n\nValidate\nWorkflow for defining a set of validations on a table and interrogating for results.\n\n\nThresholds\nDefinition of threshold values.\n\n\nSchema\nDefinition of a schema object."
  },
  {
    "objectID": "reference/index.html#validation-steps",
    "href": "reference/index.html#validation-steps",
    "title": "API Reference",
    "section": "",
    "text": "Validation steps can be thought of as sequential validations on the target data. We call Validate’s validation methods to build up a validation plan: a collection of steps that, in the aggregate, provides good validation coverage.\n\n\n\nValidate.col_vals_gt\nAre column data greater than a fixed value or data in another column?\n\n\nValidate.col_vals_lt\nAre column data less than a fixed value or data in another column?\n\n\nValidate.col_vals_ge\nAre column data greater than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_le\nAre column data less than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_eq\nAre column data equal to a fixed value or data in another column?\n\n\nValidate.col_vals_ne\nAre column data not equal to a fixed value or data in another column?\n\n\nValidate.col_vals_between\nDo column data lie between two specified values or data in other columns?\n\n\nValidate.col_vals_outside\nDo column data lie outside of two specified values or data in other columns?\n\n\nValidate.col_vals_in_set\nValidate whether column values are in a set of values.\n\n\nValidate.col_vals_not_in_set\nValidate whether column values are not in a set of values.\n\n\nValidate.col_vals_null\nValidate whether values in a column are NULL.\n\n\nValidate.col_vals_not_null\nValidate whether values in a column are not NULL.\n\n\nValidate.col_vals_regex\nValidate whether column values match a regular expression pattern.\n\n\nValidate.col_exists\nValidate whether one or more columns exist in the table.\n\n\nValidate.rows_distinct\nValidate whether rows in the table are distinct.\n\n\nValidate.col_schema_match\nDo columns in the table (and their types) match a predefined schema?\n\n\ncol\nHelper function for referencing a column in the input table."
  },
  {
    "objectID": "reference/index.html#interrogation-and-reporting",
    "href": "reference/index.html#interrogation-and-reporting",
    "title": "API Reference",
    "section": "",
    "text": "The validation plan is put into action when interrogate() is called. The workflow for performing a comprehensive validation is then: (1) Validate(), (2) , (3) interrogate(). After interrogation of the data, we can view a validation table (by printing the object or using get_tabular_report()), extract key metrics, or split the data based on the validation results (with get_sundered_data()).\n\n\n\nValidate.interrogate\nExecute each validation step against the table and store the results.\n\n\nValidate.get_data_extracts\nGet the rows that failed for each validation step.\n\n\nValidate.get_json_report\nGet a report of the validation results as a JSON-formatted string.\n\n\nValidate.get_tabular_report\nValidation report as a GT table.\n\n\nValidate.get_sundered_data\nGet the data that passed or failed the validation steps.\n\n\nValidate.all_passed\nDetermine if every validation step passed perfectly, with no failing test units.\n\n\nValidate.n\nProvides a dictionary of the number of test units for each validation step.\n\n\nValidate.n_passed\nProvides a dictionary of the number of test units that passed for each validation step.\n\n\nValidate.n_failed\nProvides a dictionary of the number of test units that failed for each validation step.\n\n\nValidate.f_passed\nProvides a dictionary of the fraction of test units that passed for each validation step.\n\n\nValidate.f_failed\nProvides a dictionary of the fraction of test units that failed for each validation step.\n\n\nValidate.warn\nProvides a dictionary of the warning status for each validation step.\n\n\nValidate.stop\nProvides a dictionary of the stopping status for each validation step.\n\n\nValidate.notify\nProvides a dictionary of the notification status for each validation step."
  },
  {
    "objectID": "reference/index.html#utilities",
    "href": "reference/index.html#utilities",
    "title": "API Reference",
    "section": "",
    "text": "The utilities group contain functions that are helpful for the validation process. We can load datasets with load_dataset() and set global configuration parameters with config().\n\n\n\nload_dataset\nLoad a dataset hosted in the library as specified DataFrame type.\n\n\nconfig\nConfiguration settings for the pointblank library."
  },
  {
    "objectID": "reference/Validate.html",
    "href": "reference/Validate.html",
    "title": "Validate",
    "section": "",
    "text": "Validate(self, data, tbl_name=None, label=None, thresholds=None)\nWorkflow for defining a set of validations on a table and interrogating for results.\nThe Validate class is used for defining a set of validation steps on a table and interrogating the table with the validation plan. This class is the main entry point for the data quality reporting workflow. The overall aim of this workflow is to generate comprehensive reporting information to assess the level of data quality for a target table.\nWe can supply as many validation steps as needed, and having a large number of them should increase the validation coverage for a given table. The validation methods (e.g., col_vals_gt(), col_vals_between(), etc.) translate to discrete validation steps, where each step will be sequentially numbered (useful when viewing the reporting data). This process of calling validation methods is known as developing a validation plan.\nThe validation methods, when called, are merely instructions up to the point the concluding interrogate() method is called. That kicks off the process of acting on the validation plan by querying the target table getting reporting results for each step. Once the interrogation process is complete, we can say that the workflow now has reporting information. We can then extract useful information from the reporting data to understand the quality of the table. For instance get_tabular_report() method which will return a table with the results of the interrogation and get_sundered_data() allows for the splitting of the table based on passing and failing rows."
  },
  {
    "objectID": "reference/Validate.html#parameters",
    "href": "reference/Validate.html#parameters",
    "title": "Validate",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table to validate, which could be a DataFrame object or an Ibis table object. Read the Supported Input Table Types section for details on the supported table types.\n\ntbl_name : str | None = None\n\nA optional name to assign to the input table object. If no value is provided, a name will be generated based on whatever information is available. This table name will be displayed in the header area of the HTML report generated by using the get_tabular_report() method.\n\nlabel : str | None = None\n\nAn optional label for the validation plan. If no value is provided, a label will be generated based on the current system date and time. Markdown can be used here to make the label more visually appealing (it will appear in the header area of the HTML report).\n\nthresholds : int | float | bool | tuple | dict | Thresholds | None = None\n\nGenerate threshold failure levels so that all validation steps can report and react accordingly when exceeding the set levels. This is to be created using one of several valid input schemes: (1) single integer/float denoting absolute number or fraction of failing test units for the ‘warn’ level, (2) a tuple of 1-3 values, (3) a dictionary of 1-3 entries, or a Thresholds object."
  },
  {
    "objectID": "reference/Validate.html#returns",
    "href": "reference/Validate.html#returns",
    "title": "Validate",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nA Validate object with the table and validations to be performed."
  },
  {
    "objectID": "reference/Validate.html#supported-input-table-types",
    "href": "reference/Validate.html#supported-input-table-types",
    "title": "Validate",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nParquet table (\"parquet\")*\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, the use of Validate with such tables requires the Ibis library v9.5.0 and above to be installed. If the input table is a Polars or Pandas DataFrame, the Ibis library is not required."
  },
  {
    "objectID": "reference/Validate.html#examples",
    "href": "reference/Validate.html#examples",
    "title": "Validate",
    "section": "Examples",
    "text": "Examples"
  },
  {
    "objectID": "reference/Validate.html#creating-a-validation-plan-and-interrogating",
    "href": "reference/Validate.html#creating-a-validation-plan-and-interrogating",
    "title": "Validate",
    "section": "Creating a validation plan and interrogating",
    "text": "Creating a validation plan and interrogating\nLet’s walk through a data quality analysis of an extremely small table. It’s actually called small_table and it’s accessible through the load_dataset() function.\n\nimport pointblank as pb\n\n# Load the small_table dataset\nsmall_table = pb.load_dataset()\n\nsmall_table\n\n\nshape: (13, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"2016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"……………………2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"2016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"2016-01-30 11:23:002016-01-301\"3-dka-303\"null2230.09true\"high\"\n\n\nWe ought to think about what’s tolerable in terms of data quality so let’s designate proportional failure thresholds to the warn, stop, and notify states. This can be done by using the Thresholds class.\n\nthresholds = pb.Thresholds(warn_at=0.10, stop_at=0.25, notify_at=0.35)\n\nNow, we use the Validate class and give it the thresholds object (which serves as a default for all validation steps but can be overridden). The static thresholds provided in thresholds will make the reporting a bit more useful. We also need to provide a target table and we’ll use small_table for this.\n\nvalidation = (\n    pb.Validate(\n        data=small_table,\n        tbl_name=\"small_table\",\n        label=\"`Validate` example.\",\n        thresholds=thresholds\n    )\n)\n\nThen, as with any Validate object, we can add steps to the validation plan by using as many validation methods as we want. To conclude the process (and actually query the data table), we use the interrogate() method.\n\nvalidation = (\n    validation\n    .col_vals_gt(columns=\"d\", value=100)\n    .col_vals_le(columns=\"c\", value=5)\n    .col_vals_between(columns=\"c\", left=3, right=10, na_pass=True)\n    .col_vals_regex(columns=\"b\", pattern=r\"[0-9]-[a-z]{3}-[0-9]{3}\")\n    .col_exists(columns=[\"date\", \"date_time\"])\n    .interrogate()\n)\n\nThe validation object can be printed as a reporting table.\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    `Validate` example.Polarssmall_tableWARN0.1STOP0.25NOTIFY0.35\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #CF142B\n    2\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    c\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    60.46\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n        \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_between()\n        \n    c\n    [3, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    b\n    [0-9]-[a-z]{3}-[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:49:05 UTC&lt; 1 s2025-01-02 04:49:05 UTC"
  },
  {
    "objectID": "reference/Thresholds.html",
    "href": "reference/Thresholds.html",
    "title": "Thresholds",
    "section": "",
    "text": "Thresholds(self, warn_at=None, stop_at=None, notify_at=None)\nDefinition of threshold values.\n\n\n\nwarn_at : int | float | bool | None = None\n\nThe threshold for the ‘warn’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1.\n\nstop_at : int | float | bool | None = None\n\nThe threshold for the ‘stop’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1.\n\nnotify_at : int | float | bool | None = None\n\nThe threshold for the ‘notify’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1.\n\n\n\n\n\n\n : Thresholds\n\nA Thresholds object. This can be used when using the Validate class (to set thresholds globally) or when defining validation steps through Validate’s methods (so that threshold values are scoped to individual validation steps, overriding any global thresholds)."
  },
  {
    "objectID": "reference/Thresholds.html#parameters",
    "href": "reference/Thresholds.html#parameters",
    "title": "Thresholds",
    "section": "",
    "text": "warn_at : int | float | bool | None = None\n\nThe threshold for the ‘warn’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1.\n\nstop_at : int | float | bool | None = None\n\nThe threshold for the ‘stop’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1.\n\nnotify_at : int | float | bool | None = None\n\nThe threshold for the ‘notify’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold to 1."
  },
  {
    "objectID": "reference/Thresholds.html#returns",
    "href": "reference/Thresholds.html#returns",
    "title": "Thresholds",
    "section": "",
    "text": ": Thresholds\n\nA Thresholds object. This can be used when using the Validate class (to set thresholds globally) or when defining validation steps through Validate’s methods (so that threshold values are scoped to individual validation steps, overriding any global thresholds)."
  },
  {
    "objectID": "reference/col.html",
    "href": "reference/col.html",
    "title": "col",
    "section": "",
    "text": "col(name)\nHelper function for referencing a column in the input table.\nMany of the validation methods (i.e., col_vals_*() methods) in pointblank have a value= argument. These validations are comparisons between column values and a literal value, or, between column values and adjacent values in another column. The col() helper function is used to specify that it is a column being referenced, not a literal value.\nThe col() doesn’t check that the column exists in the input table. It acts to signal that the value being compared is a column value. During validation (i.e., when interrogate() is called), pointblank will then check that the column exists in the input table.\nThis function can be used in the value= argument of the following validation methods:\nFor the last two methods cited, col() can be used with either of the left= and right= arguments, or both."
  },
  {
    "objectID": "reference/col.html#parameters",
    "href": "reference/col.html#parameters",
    "title": "col",
    "section": "Parameters",
    "text": "Parameters\n\nname : str\n\nThe name of the column in the input table."
  },
  {
    "objectID": "reference/col.html#returns",
    "href": "reference/col.html#returns",
    "title": "col",
    "section": "Returns",
    "text": "Returns\n\n : Column\n\nA Column object representing the column."
  },
  {
    "objectID": "reference/col.html#examples",
    "href": "reference/col.html#examples",
    "title": "col",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns a and b and we’d like to validate that the values in column a are greater than the values in column b. We can use the col() helper function to reference the comparison column when creating the validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 6, 5],\n        \"b\": [4, 2, 3, 3, 4, 3],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the excerpt of the validation table, values in a were greater than values in b for every row (or test unit). Using value=pb.col(\"b\") specified that the greater-than comparison is across columns, not with a fixed literal value."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html",
    "href": "reference/Validate.get_tabular_report.html",
    "title": "Validate.get_tabular_report",
    "section": "",
    "text": "Validate.get_tabular_report(\n    title=':default:',\n    incl_header=None,\n    incl_footer=None,\n)\nValidation report as a GT table.\nThe get_tabular_report() method returns a GT table object that represents the validation report. This validation table provides a summary of the validation results, including the validation steps, the number of test units, the number of failing test units, and the fraction of failing test units. The table also includes status indicators for the warn, stop, and notify levels.\nYou could simply display the validation table without the use of the get_tabular_report() method. However, the method provides a way to customize the title of the report. In the future this method may provide additional options for customizing the report."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#parameters",
    "href": "reference/Validate.get_tabular_report.html#parameters",
    "title": "Validate.get_tabular_report",
    "section": "Parameters",
    "text": "Parameters\n\ntitle : str | None = ':default:'\n\nOptions for customizing the title of the report. The default is the \":default:\" value which produces a generic title. Another option is \":tbl_name:\", and that presents the name of the table as the title for the report. If no title is wanted, then \":none:\" can be used. Aside from keyword options, text can be provided for the title. This will be interpreted as Markdown text and transformed internally to HTML."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#returns",
    "href": "reference/Validate.get_tabular_report.html#returns",
    "title": "Validate.get_tabular_report",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT table object that represents the validation report."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#examples",
    "href": "reference/Validate.get_tabular_report.html#examples",
    "title": "Validate.get_tabular_report",
    "section": "Examples",
    "text": "Examples\nLet’s create a Validate object with a few validation steps and then interrogate the data table to see how it performs against the validation plan. We can then generate a tabular report to get a summary of the results.\n\nimport pointblank as pb\nimport polars as pl\n\n# Create a Polars DataFrame\ntbl_pl = pl.DataFrame({\"x\": [1, 2, 3, 4], \"y\": [4, 5, 6, 7]})\n\n# Validate data using Polars DataFrame\nvalidation = (\n    pb.Validate(data=tbl_pl, tbl_name=\"tbl_xy\", thresholds=(2, 3, 4))\n    .col_vals_gt(columns=\"x\", value=1)\n    .col_vals_lt(columns=\"x\", value=3)\n    .col_vals_le(columns=\"y\", value=7)\n    .interrogate()\n)\n\n# Look at the validation table\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:48:52Polarstbl_xyWARN2STOP3NOTIFY4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #FFBF00\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:48:52 UTC&lt; 1 s2025-01-02 04:48:52 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe validation table is displayed with a default title (‘Validation Report’). We can use the get_tabular_report() method to customize the title of the report. For example, we can set the title to the name of the table by using the title=\":tbl_name:\" option. This will use the string provided in the tbl_name= argument of the Validate object.\n\nvalidation.get_tabular_report(title=\":tbl_name:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    tbl_xy\n  \n  \n    2025-01-02|04:48:52Polarstbl_xyWARN2STOP3NOTIFY4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #FFBF00\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:48:52 UTC&lt; 1 s2025-01-02 04:48:52 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe title of the report is now set to the name of the table, which is ‘tbl_xy’. This can be useful if you have multiple tables and want to keep track of which table the validation report is for.\nAlternatively, you can provide your own title for the report.\n\nvalidation.get_tabular_report(title=\"Report for Table XY\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Table XY\n\n  \n  \n    2025-01-02|04:48:52Polarstbl_xyWARN2STOP3NOTIFY4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #FFBF00\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:48:52 UTC&lt; 1 s2025-01-02 04:48:52 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe title of the report is now set to ‘Report for Table XY’. This can be useful if you want to provide a more descriptive title for the report."
  },
  {
    "objectID": "reference/Validate.n.html",
    "href": "reference/Validate.n.html",
    "title": "Validate.n",
    "section": "",
    "text": "Validate.n(i=None, scalar=False)\nProvides a dictionary of the number of test units for each validation step.\nThe n() method provides the number of test units for each validation step. This is the total number of test units that were evaluated in the validation step. It is always an integer value.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. The total number of test units for a validation step is the sum of the number of passing and failing test units (i.e., n = n_passed + n_failed)."
  },
  {
    "objectID": "reference/Validate.n.html#parameters",
    "href": "reference/Validate.n.html#parameters",
    "title": "Validate.n",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n.html#returns",
    "href": "reference/Validate.n.html#returns",
    "title": "Validate.n",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n.html#examples",
    "href": "reference/Validate.n.html#examples",
    "title": "Validate.n",
    "section": "Examples",
    "text": "Examples\nDifferent types of validation steps can have different numbers of test units. In the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the number of test units for each step will be a little bit different.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 9, 5],\n        \"b\": [5, 6, 10, 3],\n        \"c\": [\"a\", \"b\", \"a\", \"a\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_exists(columns=\"b\")\n    .col_vals_lt(columns=\"b\", value=9, pre=lambda df: df.filter(pl.col(\"a\") &gt; 1))\n    .interrogate()\n)\n\nThe first validation step checks that all values in column a are greater than 0. Let’s use the n() method to determine the number of test units this validation step.\n\nvalidation.n(i=1, scalar=True)\n\n4\n\n\nThe returned value of 4 is the number of test units for the first validation step. This value is the same as the number of rows in the table.\nThe second validation step checks for the existence of column b. Using the n() method we can get the number of test units for this the second step.\n\nvalidation.n(i=2, scalar=True)\n\n1\n\n\nThere’s a single test unit here because the validation step is checking for the presence of a single column.\nThe third validation step checks that all values in column b are less than 9 after filtering the table to only include rows where the value in column a is greater than 1. Because the table is filtered, the number of test units will be less than the total number of rows in the input table. Let’s prove this by using the n() method.\n\nvalidation.n(i=3, scalar=True)\n\n3\n\n\nThe returned value of 3 is the number of test units for the third validation step. When using the pre= argument, the input table can be mutated before performing the validation. The n() method is a good way to determine whether the mutation performed as expected.\nIn all of these examples, the scalar=True argument was used to return the value as a scalar integer value. If scalar=False, the method will return a dictionary with an entry for the validation step number (from the i= argument) and the number of test units. Futhermore, leaving out the i= argument altogether will return a dictionary with filled with the number of test units for each validation step. Here’s what that looks like:\n\nvalidation.n()\n\n{1: 4, 2: 1, 3: 3}"
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html",
    "href": "reference/Validate.col_vals_ge.html",
    "title": "Validate.col_vals_ge",
    "section": "",
    "text": "Validate.col_vals_ge(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data greater than or equal to a fixed value or data in another column?\nThe col_vals_ge() validation method checks whether column values in a table are greater than or equal to a specified value= (the exact comparison used in this function is col_val &gt;= value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#parameters",
    "href": "reference/Validate.col_vals_ge.html#parameters",
    "title": "Validate.col_vals_ge",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#returns",
    "href": "reference/Validate.col_vals_ge.html#returns",
    "title": "Validate.col_vals_ge",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#examples",
    "href": "reference/Validate.col_vals_ge.html#examples",
    "title": "Validate.col_vals_ge",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [5, 3, 1, 8, 2, 3],\n        \"c\": [2, 3, 1, 4, 3, 4],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64552633511984723534\n\n\nLet’s validate that values in column a are all greater than or equal to the value of 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ge(columns=\"a\", value=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_gte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_ge()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_ge(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_ge() to check whether the values in column b are greater than values in column c.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ge(columns=\"b\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_ge()\n        \n    b\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 0: b is 2 and c is 3.\nRow 4: b is 3 and c is 4."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html",
    "href": "reference/Validate.col_vals_eq.html",
    "title": "Validate.col_vals_eq",
    "section": "",
    "text": "Validate.col_vals_eq(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data equal to a fixed value or data in another column?\nThe col_vals_eq() validation method checks whether column values in a table are equal to a specified value= (the exact comparison used in this function is col_val == value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#parameters",
    "href": "reference/Validate.col_vals_eq.html#parameters",
    "title": "Validate.col_vals_eq",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#returns",
    "href": "reference/Validate.col_vals_eq.html#returns",
    "title": "Validate.col_vals_eq",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#examples",
    "href": "reference/Validate.col_vals_eq.html#examples",
    "title": "Validate.col_vals_eq",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 5, 5, 5, 5, 5],\n        \"b\": [5, 5, 5, 6, 5, 4],\n    }\n)\n\ntbl\n\n\nshape: (6, 2)abi64i64555555565554\n\n\nLet’s validate that values in column a are all equal to the value of 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_eq(columns=\"a\", value=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_equal\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_eq()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_eq(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_eq() to check whether the values in column a are equal to the values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_eq(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_equal\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_eq()\n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 3: a is 5 and b is 6.\nRow 5: a is 5 and b is 4."
  },
  {
    "objectID": "reference/Validate.n_failed.html",
    "href": "reference/Validate.n_failed.html",
    "title": "Validate.n_failed",
    "section": "",
    "text": "Validate.n_failed(i=None, scalar=False)\nProvides a dictionary of the number of test units that failed for each validation step.\nThe n_failed() method provides the number of test units that failed for each validation step. This is the number of test units that did not pass in the the validation step. It is always some integer value between 0 and the total number of test units.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of failing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the n_passed() method (i.e., n - n_passed)."
  },
  {
    "objectID": "reference/Validate.n_failed.html#parameters",
    "href": "reference/Validate.n_failed.html#parameters",
    "title": "Validate.n_failed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of failing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n_failed.html#returns",
    "href": "reference/Validate.n_failed.html#returns",
    "title": "Validate.n_failed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of failing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n_failed.html#examples",
    "href": "reference/Validate.n_failed.html#examples",
    "title": "Validate.n_failed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps and, as it turns out, all of them will have failing test units. After interrogation, the n_failed() method is used to determine the number of failing test units for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12],\n        \"b\": [9, 8, 10, 5, 10],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.n_failed()\n\n{1: 1, 2: 2, 3: 1}\n\n\nThe returned dictionary shows that all validation steps had failing test units.\nIf we wanted to check the number of failing test units for a single validation step, we can provide the step number. Also, we could forego the dictionary and get a scalar value by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.n_failed(i=1)\n\n{1: 1}\n\n\nThe returned value of 1 is the number of failing test units for the first validation step."
  },
  {
    "objectID": "reference/Validate.col_exists.html",
    "href": "reference/Validate.col_exists.html",
    "title": "Validate.col_exists",
    "section": "",
    "text": "Validate.col_exists(columns, thresholds=None, active=True)\nValidate whether one or more columns exist in the table.\nThe col_exists() method checks whether one or more columns exist in the target table. The only requirement is specification of the column names. Each validation step or expectation will operate over a single test unit, which is whether the column exists or not."
  },
  {
    "objectID": "reference/Validate.col_exists.html#parameters",
    "href": "reference/Validate.col_exists.html#parameters",
    "title": "Validate.col_exists",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_exists.html#returns",
    "href": "reference/Validate.col_exists.html#returns",
    "title": "Validate.col_exists",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_exists.html#examples",
    "href": "reference/Validate.col_exists.html#examples",
    "title": "Validate.col_exists",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with a string columns (a) and a numeric column (b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"apple\", \"banana\", \"cherry\", \"date\"],\n        \"b\": [1, 6, 3, 5],\n    }\n)\n\ntbl\n\n\nshape: (4, 2)abstri64\"apple\"1\"banana\"6\"cherry\"3\"date\"5\n\n\nLet’s validate that the columns a and b actually exist in the table. We’ll determine if this validation had any failing test units (each validation will have a single test unit).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_exists(columns=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows two entries (one check per column) generated by the col_exists() validation step. Both steps passed since both columns provided in columns= are present in the table.\nNow, let’s check for the existence of a different set of columns.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_exists(columns=[\"b\", \"c\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n        \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n         col_exists()\n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports one passing validation step (the check for column b) and one failing validation step (the check for column c, which doesn’t exist)."
  },
  {
    "objectID": "reference/Validate.all_passed.html",
    "href": "reference/Validate.all_passed.html",
    "title": "Validate.all_passed",
    "section": "",
    "text": "Validate.all_passed()\nDetermine if every validation step passed perfectly, with no failing test units.\nThe all_passed() method determines if every validation step passed perfectly, with no failing test units. This method is useful for quickly checking if the table passed all validation steps with flying colors. If there’s even a single failing test unit in any validation step, this method will return False.\nThis validation metric might be overly stringent for some validation plans where failing test units are generally expected (and the strategy is to monitor data quality over time). However, the value of all_passed() could be suitable for validation plans designed to ensure that every test unit passes perfectly (e.g., checks for column presence, null-checking tests, etc.)."
  },
  {
    "objectID": "reference/Validate.all_passed.html#returns",
    "href": "reference/Validate.all_passed.html#returns",
    "title": "Validate.all_passed",
    "section": "Returns",
    "text": "Returns\n\n : bool\n\nTrue if all validation steps had no failing test units, False otherwise."
  },
  {
    "objectID": "reference/Validate.all_passed.html#examples",
    "href": "reference/Validate.all_passed.html#examples",
    "title": "Validate.all_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the second step will have a failing test unit (the value 10 isn’t less than 9). After interrogation, the all_passed() method is used to determine if all validation steps passed perfectly.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 9, 5],\n        \"b\": [5, 6, 10, 3],\n        \"c\": [\"a\", \"b\", \"a\", \"a\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_vals_lt(columns=\"b\", value=9)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.all_passed()\n\nFalse\n\n\nThe returned value is False since the second validation step had a failing test unit. If it weren’t for that one failing test unit, the return value would have been True."
  },
  {
    "objectID": "reference/Validate.f_failed.html",
    "href": "reference/Validate.f_failed.html",
    "title": "Validate.f_failed",
    "section": "",
    "text": "Validate.f_failed(i=None, scalar=False)\nProvides a dictionary of the fraction of test units that failed for each validation step.\nA measure of the fraction of test units that failed is provided by the f_failed attribute. This is the fraction of test units that failed the validation step over the total number of test units. Given this is a fractional value, it will always be in the range of 0 to 1.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThis method provides a dictionary of the fraction of failing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the f_passed() method (i.e., 1 - f_passed())."
  },
  {
    "objectID": "reference/Validate.f_failed.html#parameters",
    "href": "reference/Validate.f_failed.html#parameters",
    "title": "Validate.f_failed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the fraction of failing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.f_failed.html#returns",
    "href": "reference/Validate.f_failed.html#returns",
    "title": "Validate.f_failed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, float] | float\n\nA dictionary of the fraction of failing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.f_failed.html#examples",
    "href": "reference/Validate.f_failed.html#examples",
    "title": "Validate.f_failed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, all having some failing test units. After interrogation, the f_failed() method is used to determine the fraction of failing test units for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\", \"d\", \"c\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.f_failed()\n\n{1: 0.2857142857142857, 2: 0.42857142857142855, 3: 0.42857142857142855}\n\n\nThe returned dictionary shows the fraction of failing test units for each validation step. The values are all greater than 0 since there were failing test units in each step.\nIf we wanted to check the fraction of failing test units for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.f_failed(i=1)\n\n{1: 0.2857142857142857}\n\n\nThe returned value is the proportion of failing test units for the first validation step (2 failing test units out of 7 total test units)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html",
    "href": "reference/Validate.col_vals_gt.html",
    "title": "Validate.col_vals_gt",
    "section": "",
    "text": "Validate.col_vals_gt(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data greater than a fixed value or data in another column?\nThe col_vals_gt() validation method checks whether column values in a table are greater than a specified value= (the exact comparison used in this function is col_val &gt; value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#parameters",
    "href": "reference/Validate.col_vals_gt.html#parameters",
    "title": "Validate.col_vals_gt",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#returns",
    "href": "reference/Validate.col_vals_gt.html#returns",
    "title": "Validate.col_vals_gt",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#examples",
    "href": "reference/Validate.col_vals_gt.html#examples",
    "title": "Validate.col_vals_gt",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 6, 5],\n        \"b\": [1, 2, 1, 2, 2, 2],\n        \"c\": [2, 1, 2, 2, 3, 4],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64512621512722623524\n\n\nLet’s validate that values in column a are all greater than the value of 4. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=4)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    4\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_gt(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_gt() to check whether the values in column c are greater than values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"c\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    c\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 1: c is 1 and b is 2.\nRow 3: c is 2 and b is 2."
  },
  {
    "objectID": "reference/Schema.html",
    "href": "reference/Schema.html",
    "title": "Schema",
    "section": "",
    "text": "Schema(self, columns=None, tbl=None, **kwargs)\nDefinition of a schema object.\nThe schema object defines the structure of a table. Once it is defined, the object can be used in a validation workflow, using Validate and its methods, to ensure that the structure of a table matches the expected schema. The validation method that works with the schema object is called col_schema_match().\nA schema for a table can be constructed with Schema in a number of ways:\nThe schema object can also be constructed by providing a DataFrame or Ibis table object (using the tbl= parameter) and the schema will be collected from either type of object. The schema object can be printed to display the column names and dtypes. Note that if tbl= is provided then there shouldn’t be any other inputs provided through either columns= or **kwargs."
  },
  {
    "objectID": "reference/Schema.html#parameters",
    "href": "reference/Schema.html#parameters",
    "title": "Schema",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | list[tuple[str, str]] | list[tuple[str]] | dict[str, str] | None = None\n\nA list of strings (representing column names), a list of tuples (for column names and column dtypes), or a dictionary containing column and dtype information. If any of these inputs are provided here, it will take precedence over any column arguments provided via **kwargs.\n\ntbl : any | None = None\n\nA DataFrame (Polars or Pandas) or an Ibis table object from which the schema will be collected.\n\n****kwargs** :  = {}\n\nIndividual column arguments that are in the form of [column]=[dtype]. These will be ignored if the columns= parameter is not None."
  },
  {
    "objectID": "reference/Schema.html#examples",
    "href": "reference/Schema.html#examples",
    "title": "Schema",
    "section": "Examples",
    "text": "Examples\nA schema can be constructed via the Schema class in multiple ways. Let’s use the following Polars DataFrame as a basis for constructing a schema:\n\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"height\": [5.6, 6.0, 5.8]\n})\n\nYou could use provide Schema(columns=) a list of tuples containing column names and data types:\n\nschema = pb.Schema(columns=[(\"name\", \"String\"), (\"age\", \"Int64\"), (\"height\", \"Float64\")])\n\nAlternatively, you could provide a dictionary containing column names and dtypes:\n\nschema = pb.Schema(columns={\"name\": \"String\", \"age\": \"Int64\", \"height\": \"Float64\"})\n\nYou could also provide individual column arguments in the form of keyword arguments:\n\nschema = pb.Schema(name=\"String\", age=\"Int64\", height=\"Float64\")\n\nFinally, could also provide a DataFrame or Ibis table object from which the schema will be collected:\nschema = pb.Schema(tbl=df)\nWhichever method you choose, you can verify the schema inputs by printing the schema object:\n\nprint(schema)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nThe Schema object can be used to validate the structure of a table against the schema. The relevant Validate method for this is col_schema_match(). In a validation workflow, you’ll have a target table (defined at the beginning of the workflow) and you might want to ensure that your expectations of the table structure are met. The col_schema_match() method works with a Schema object to validate the structure of the table. Here’s an example of how you could use the col_schema_match() method in a validation workflow:\n\nimport pointblank as pb\n\n# Define the schema\nschema = pb.Schema(name=\"String\", age=\"Int64\", height=\"Float64\")\n\n# Define a validation that checks the schema against the table (`df`)\nvalidation = (\n    pb.Validate(data=df)\n    .col_schema_match(schema)\n    .interrogate()\n)\n\n# Display the validation results\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n         col_schema_match()\n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation method will validate the structure of the table against the schema during interrogation. If the structure of the table does not match the schema, the single test unit will fail. In this case, the defined schema matched the structure of the table, so the validation passed."
  },
  {
    "objectID": "reference/Validate.notify.html",
    "href": "reference/Validate.notify.html",
    "title": "Validate.notify",
    "section": "",
    "text": "Validate.notify(i=None, scalar=False)\nProvides a dictionary of the notification status for each validation step.\nThe notification status (notify) for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the notification level. Otherwise, the status is False.\nThe ascribed name of notify is semantic and does not imply that a notification message is generated, it is simply a status indicator that could be used to trigger some sort of notification. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the notification status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.notify.html#parameters",
    "href": "reference/Validate.notify.html#parameters",
    "title": "Validate.notify",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the notification status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.notify.html#returns",
    "href": "reference/Validate.notify.html#returns",
    "title": "Validate.notify",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the notification status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.notify.html#examples",
    "href": "reference/Validate.notify.html#examples",
    "title": "Validate.notify",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have many failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe warn threshold is 2 failing test units\nthe stop threshold is 4 failing test units\nthe notify threshold is 5 failing test units\n\nAfter interrogation, the notify() method is used to determine the notify status for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [2, 4, 4, 7, 2, 3, 8],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.notify()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the notify status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the notify level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the notify level.\nWe can also visually inspect the notify status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:49:03PolarsWARN2STOP4NOTIFY5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #CF142B\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    20.29\n    50.71\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:49:03 UTC&lt; 1 s2025-01-02 04:49:03 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there are filled yellow, red, and blue circles in the first step (far right side, in the W, S, and N columns) indicating that the warn, stop, and notify thresholds were met. The other steps have empty yellow, red, and blue circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the notify status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.notify(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had the notify threshold met."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html",
    "href": "reference/Validate.col_vals_le.html",
    "title": "Validate.col_vals_le",
    "section": "",
    "text": "Validate.col_vals_le(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data less than or equal to a fixed value or data in another column?\nThe col_vals_le() validation method checks whether column values in a table are less than or equal to a specified value= (the exact comparison used in this function is col_val &lt;= value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#parameters",
    "href": "reference/Validate.col_vals_le.html#parameters",
    "title": "Validate.col_vals_le",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#returns",
    "href": "reference/Validate.col_vals_le.html#returns",
    "title": "Validate.col_vals_le",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#examples",
    "href": "reference/Validate.col_vals_le.html#examples",
    "title": "Validate.col_vals_le",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [1, 3, 1, 5, 2, 5],\n        \"c\": [2, 1, 1, 4, 3, 4],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64512631511954723554\n\n\nLet’s validate that values in column a are all less than or equal to the value of 9. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_le(columns=\"a\", value=9)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    a\n    9\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_le(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_le() to check whether the values in column c are less than values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_le(columns=\"c\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_lte\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_le()\n        \n    c\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 0: c is 2 and b is 1.\nRow 4: c is 3 and b is 2."
  },
  {
    "objectID": "reference/load_dataset.html",
    "href": "reference/load_dataset.html",
    "title": "load_dataset",
    "section": "",
    "text": "load_dataset(dataset='small_table', tbl_type='polars')\nLoad a dataset hosted in the library as specified DataFrame type."
  },
  {
    "objectID": "reference/load_dataset.html#parameters",
    "href": "reference/load_dataset.html#parameters",
    "title": "load_dataset",
    "section": "Parameters",
    "text": "Parameters\n\ndataset : Literal['small_table', 'game_revenue'] = 'small_table'\n\nThe name of the dataset to load. Current options are \"small_table\" and \"game_revenue\".\n\ntbl_type : Literal['polars', 'pandas', 'duckdb'] = 'polars'\n\nThe type of DataFrame to generate from the dataset. The named options are \"polars\", \"pandas\", and \"duckdb\"."
  },
  {
    "objectID": "reference/load_dataset.html#returns",
    "href": "reference/load_dataset.html#returns",
    "title": "load_dataset",
    "section": "Returns",
    "text": "Returns\n\n : FrameT | Any\n\nThe dataset for the Validate object. This could be a Polars DataFrame, a Pandas DataFrame, or a DuckDB table as an Ibis table."
  },
  {
    "objectID": "reference/load_dataset.html#examples",
    "href": "reference/load_dataset.html#examples",
    "title": "load_dataset",
    "section": "Examples",
    "text": "Examples\nLoad the small_table dataset as a Polars DataFrame by calling load_dataset() with its defaults:\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset()\n\nsmall_table\n\n\nshape: (13, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"2016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"……………………2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"2016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"2016-01-30 11:23:002016-01-301\"3-dka-303\"null2230.09true\"high\"\n\n\nThe game_revenue dataset can be loaded as a Pandas DataFrame by specifying the dataset name and setting tbl_type=\"pandas\":\n\nimport pointblank as pb\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"pandas\")\n\ngame_revenue\n\n\n\n\n  \n    \n      \n      player_id\n      session_id\n      session_start\n      time\n      item_type\n      item_name\n      item_revenue\n      session_duration\n      start_day\n      acquisition\n      country\n    \n  \n  \n    \n      0\n      ECPANOIXLZHF896\n      ECPANOIXLZHF896-eol2j8bs\n      2015-01-01 01:31:03+00:00\n      2015-01-01 01:31:27+00:00\n      iap\n      offer2\n      8.991\n      16.3\n      2015-01-01\n      google\n      Germany\n    \n    \n      1\n      ECPANOIXLZHF896\n      ECPANOIXLZHF896-eol2j8bs\n      2015-01-01 01:31:03+00:00\n      2015-01-01 01:36:57+00:00\n      iap\n      gems3\n      22.491\n      16.3\n      2015-01-01\n      google\n      Germany\n    \n    \n      2\n      ECPANOIXLZHF896\n      ECPANOIXLZHF896-eol2j8bs\n      2015-01-01 01:31:03+00:00\n      2015-01-01 01:37:45+00:00\n      iap\n      gold7\n      107.991\n      16.3\n      2015-01-01\n      google\n      Germany\n    \n    \n      3\n      ECPANOIXLZHF896\n      ECPANOIXLZHF896-eol2j8bs\n      2015-01-01 01:31:03+00:00\n      2015-01-01 01:42:33+00:00\n      ad\n      ad_20sec\n      0.760\n      16.3\n      2015-01-01\n      google\n      Germany\n    \n    \n      4\n      ECPANOIXLZHF896\n      ECPANOIXLZHF896-hdu9jkls\n      2015-01-01 11:50:02+00:00\n      2015-01-01 11:55:20+00:00\n      ad\n      ad_5sec\n      0.030\n      35.2\n      2015-01-01\n      google\n      Germany\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      NAOJRDMCSEBI281\n      NAOJRDMCSEBI281-j2vs9ilp\n      2015-01-21 01:57:50+00:00\n      2015-01-21 02:02:50+00:00\n      ad\n      ad_survey\n      1.332\n      25.8\n      2015-01-11\n      organic\n      Norway\n    \n    \n      1996\n      NAOJRDMCSEBI281\n      NAOJRDMCSEBI281-j2vs9ilp\n      2015-01-21 01:57:50+00:00\n      2015-01-21 02:22:14+00:00\n      ad\n      ad_survey\n      1.350\n      25.8\n      2015-01-11\n      organic\n      Norway\n    \n    \n      1997\n      RMOSWHJGELCI675\n      RMOSWHJGELCI675-vbhcsmtr\n      2015-01-21 02:39:48+00:00\n      2015-01-21 02:40:00+00:00\n      ad\n      ad_5sec\n      0.030\n      8.4\n      2015-01-10\n      other_campaign\n      France\n    \n    \n      1998\n      RMOSWHJGELCI675\n      RMOSWHJGELCI675-vbhcsmtr\n      2015-01-21 02:39:48+00:00\n      2015-01-21 02:47:12+00:00\n      iap\n      offer5\n      26.091\n      8.4\n      2015-01-10\n      other_campaign\n      France\n    \n    \n      1999\n      GJCXNTWEBIPQ369\n      GJCXNTWEBIPQ369-9elq67md\n      2015-01-21 03:59:23+00:00\n      2015-01-21 04:06:29+00:00\n      ad\n      ad_5sec\n      0.120\n      18.5\n      2015-01-14\n      organic\n      United States\n    \n  \n\n2000 rows × 11 columns"
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html",
    "href": "reference/Validate.col_vals_outside.html",
    "title": "Validate.col_vals_outside",
    "section": "",
    "text": "Validate.col_vals_outside(\n    columns,\n    left,\n    right,\n    inclusive=(True, True),\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nDo column data lie outside of two specified values or data in other columns?\nThe col_vals_between() validation method checks whether column values in a table do not fall within a certain range. The range is specified with three arguments: left=, right=, and inclusive=. The left= and right= values specify the lower and upper bounds. These bounds can be specified as literal values or as column names provided within col(). The validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#parameters",
    "href": "reference/Validate.col_vals_outside.html#parameters",
    "title": "Validate.col_vals_outside",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nleft : float | int | Column\n\nThe lower bound of the range. Can be a single numeric value or a column name given in col().\n\nright : float | int | Column\n\nThe upper bound of the range. Can be a single numeric value or a column name given in col().\n\ninclusive : tuple[bool, bool] = (True, True)\n\nA tuple of two boolean values indicating whether the comparison should be inclusive. The position of the boolean values correspond to the left= and right= values, respectively. By default, both values are True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#returns",
    "href": "reference/Validate.col_vals_outside.html#returns",
    "title": "Validate.col_vals_outside",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#examples",
    "href": "reference/Validate.col_vals_outside.html#examples",
    "title": "Validate.col_vals_outside",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 5, 5],\n        \"b\": [2, 3, 6, 4, 3, 6],\n        \"c\": [9, 8, 8, 9, 9, 7],\n    }\n)\n\ntbl\n\n\nshape: (6, 3)abci64i64i64529638568749539567\n\n\nLet’s validate that values in column a are all outside the fixed boundary values of 1 and 4. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_outside(columns=\"a\", left=1, right=4)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_not_between\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n         col_vals_outside()\n        \n    a\n    [1, 4]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_outside(). All test units passed, and there are no failing test units.\nAside from checking a column against two literal values representing the lower and upper bounds, we can also provide column names to the left= and/or right= arguments (by using the helper function col()). In this way, we can perform three additional comparison types:\n\nleft=column, right=column\nleft=literal, right=column\nleft=column, right=literal\n\nFor the next example, we’ll use col_vals_outside() to check whether the values in column b are outside of the range formed by the corresponding values in columns a (lower bound) and c (upper bound).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_outside(columns=\"b\", left=pb.col(\"a\"), right=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_not_between\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n         col_vals_outside()\n        \n    b\n    [a, c]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 2: b is 6 and the bounds are 5 (a) and 8 (c).\nRow 5: b is 6 and the bounds are 5 (a) and 7 (c)."
  },
  {
    "objectID": "reference/Validate.interrogate.html",
    "href": "reference/Validate.interrogate.html",
    "title": "Validate.interrogate",
    "section": "",
    "text": "Validate.interrogate(\n    collect_extracts=True,\n    collect_tbl_checked=True,\n    get_first_n=None,\n    sample_n=None,\n    sample_frac=None,\n    sample_limit=5000,\n)\nExecute each validation step against the table and store the results.\nWhen a validation plan has been set with a series of validation steps, the interrogation process through interrogate() should then be invoked. Interrogation will evaluate each validation step against the table and store the results.\nThe interrogation process will collect extracts of failing rows if the collect_extracts option is set to True (the default). We can control the number of rows collected using the get_first_n=, sample_n=, and sample_frac= options. The sample_limit= option will enforce a hard limit on the number of rows collected when using the sample_frac= option.\nAfter interrogation is complete, the Validate object will have gathered information, and we can use methods like n_passed(), f_failed(), etc., to understand how the table performed against the validation plan. A visual representation of the validation results can be viewed by printing the Validate object; this will display the validation table in an HTML viewing environment."
  },
  {
    "objectID": "reference/Validate.interrogate.html#parameters",
    "href": "reference/Validate.interrogate.html#parameters",
    "title": "Validate.interrogate",
    "section": "Parameters",
    "text": "Parameters\n\ncollect_extracts : bool = True\n\nAn option to collect rows of the input table that didn’t pass a particular validation step. The default is True and further options (i.e., get_first_n=, sample_*=) allow for fine control of how these rows are collected.\n\ncollect_tbl_checked : bool = True\n\nThe processed data frames produced by executing the validation steps is collected and stored in the Validate object if collect_tbl_checked=True. This information is necessary for some methods (e.g., get_sundered_data()), but it potentially makes the object grow to a large size. To opt out of attaching this data, set this argument to False.\n\nget_first_n : int | None = None\n\nIf the option to collect rows where test units is chosen, there is the option here to collect the first n rows. Supply an integer number of rows to extract from the top of subset table containing non-passing rows (the ordering of data from the original table is retained).\n\nsample_n : int | None = None\n\nIf the option to collect non-passing rows is chosen, this option allows for the sampling of n rows. Supply an integer number of rows to sample from the subset table. If n happens to be greater than the number of non-passing rows, then all such rows will be returned.\n\nsample_frac : int | float | None = None\n\nIf the option to collect non-passing rows is chosen, this option allows for the sampling of a fraction of those rows. Provide a number in the range of 0 and 1. The number of rows to return could be very large, however, the sample_limit= option will apply a hard limit to the returned rows.\n\nsample_limit : int = 5000\n\nA value that limits the possible number of rows returned when sampling non-passing rows using the sample_frac= option."
  },
  {
    "objectID": "reference/Validate.interrogate.html#returns",
    "href": "reference/Validate.interrogate.html#returns",
    "title": "Validate.interrogate",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the results of the interrogation."
  },
  {
    "objectID": "reference/Validate.interrogate.html#examples",
    "href": "reference/Validate.interrogate.html#examples",
    "title": "Validate.interrogate",
    "section": "Examples",
    "text": "Examples\nLet’s use a built-in dataset (\"game_revenue\") to demonstrate some of the options of the interrogation process. A series of validation steps will populate our validation plan. After setting up the plan, the next step is to interrogate the table and see how well it aligns with our expectations. We’ll use the get_first_n= option so that any extracts of failing rows are limited to the first n rows.\n\nimport polars as pl\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"game_revenue\"))\n    .col_vals_lt(columns=\"item_revenue\", value=200)\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .col_vals_gt(columns=\"session_duration\", value=5)\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n)\n\nvalidation.interrogate(get_first_n=10)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:49:19Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_lt()\n        \n    item_revenue\n    200\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19820.99\n    180.01\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n        \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n         col_vals_regex()\n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:49:19 UTC&lt; 1 s2025-01-02 04:49:19 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that step 3 (checking for session_duration greater than 5) has 18 failing test units. This means that 18 rows in the table are problematic. We’d like to see the rows that failed this validation step and we can do that with the get_data_extracts() method.\n\nvalidation.get_data_extracts(i=3, frame=True)\n\n\nshape: (10, 11)player_idsession_idsession_starttimeitem_typeitem_nameitem_revenuesession_durationstart_dayacquisitioncountrystrstrdatetime[μs, UTC]datetime[μs, UTC]strstrf64f64datestrstr\"QNLVRDEOXFYJ892\"\"QNLVRDEOXFYJ892-lz5fmr6k\"2015-01-10 16:44:17 UTC2015-01-10 16:45:29 UTC\"iap\"\"gold3\"3.4933.72015-01-09\"crosspromo\"\"Australia\"\"RMOSWHJGELCI675\"\"RMOSWHJGELCI675-t4y8bjcu\"2015-01-11 07:24:24 UTC2015-01-11 07:25:18 UTC\"iap\"\"offer4\"17.9915.02015-01-10\"other_campaign\"\"France\"\"RMOSWHJGELCI675\"\"RMOSWHJGELCI675-t4y8bjcu\"2015-01-11 07:24:24 UTC2015-01-11 07:26:24 UTC\"iap\"\"offer5\"26.0915.02015-01-10\"other_campaign\"\"France\"\"RMOSWHJGELCI675\"\"RMOSWHJGELCI675-t4y8bjcu\"2015-01-11 07:24:24 UTC2015-01-11 07:28:36 UTC\"ad\"\"ad_15sec\"0.535.02015-01-10\"other_campaign\"\"France\"\"GFLYJHAPMZWD631\"\"GFLYJHAPMZWD631-i2v1bl7a\"2015-01-11 16:13:24 UTC2015-01-11 16:14:54 UTC\"iap\"\"gems2\"3.9963.62015-01-09\"organic\"\"India\"\"BFNLURISJXTH647\"\"BFNLURISJXTH647-6o5hx27z\"2015-01-12 17:37:39 UTC2015-01-12 17:39:27 UTC\"iap\"\"offer5\"11.5964.12015-01-10\"organic\"\"India\"\"BFNLURISJXTH647\"\"BFNLURISJXTH647-6o5hx27z\"2015-01-12 17:37:39 UTC2015-01-12 17:41:45 UTC\"iap\"\"gems3\"9.9964.12015-01-10\"organic\"\"India\"\"KILWZYHRSJEG316\"\"KILWZYHRSJEG316-uke7dhqj\"2015-01-13 22:16:29 UTC2015-01-13 22:17:35 UTC\"iap\"\"offer2\"10.9893.22015-01-04\"organic\"\"Denmark\"\"JUBDVFHCNQWT198\"\"JUBDVFHCNQWT198-9h4xs2pb\"2015-01-14 16:08:25 UTC2015-01-14 16:08:43 UTC\"iap\"\"offer5\"8.6973.32015-01-14\"organic\"\"Philippines\"\"JUBDVFHCNQWT198\"\"JUBDVFHCNQWT198-9h4xs2pb\"2015-01-14 16:08:25 UTC2015-01-14 16:11:01 UTC\"iap\"\"offer4\"5.9973.32015-01-14\"organic\"\"Philippines\"\n\n\nThe get_data_extracts() method will return a Polars DataFrame with the first 10 rows that failed the validation step. There are actually 18 rows that failed but we limited the collection of extracts with get_first_n=10."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html",
    "href": "reference/Validate.rows_distinct.html",
    "title": "Validate.rows_distinct",
    "section": "",
    "text": "Validate.rows_distinct(\n    columns_subset=None,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nValidate whether rows in the table are distinct.\nThe rows_distinct() method checks whether rows in the table are distinct. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#parameters",
    "href": "reference/Validate.rows_distinct.html#parameters",
    "title": "Validate.rows_distinct",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns_subset : str | list[str] | None = None\n\nA single column or a list of columns to use as a subset for the distinct comparison. If None, then all columns in the table will be used for the comparison. If multiple columns are supplied, the distinct comparison will be made over the combination of values in those columns.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#returns",
    "href": "reference/Validate.rows_distinct.html#returns",
    "title": "Validate.rows_distinct",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#examples",
    "href": "reference/Validate.rows_distinct.html#examples",
    "title": "Validate.rows_distinct",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three string columns (col_1, col_2, and col_3). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"col_1\": [\"a\", \"b\", \"c\", \"d\"],\n        \"col_2\": [\"a\", \"a\", \"c\", \"d\"],\n        \"col_3\": [\"a\", \"a\", \"d\", \"e\"],\n    }\n)\n\ntbl\n\n\nshape: (4, 3)col_1col_2col_3strstrstr\"a\"\"a\"\"a\"\"b\"\"a\"\"a\"\"c\"\"c\"\"d\"\"d\"\"d\"\"e\"\n\n\nLet’s validate that the rows in the table are distinct with rows_distinct(). We’ll determine if this validation had any failing test units (there are four test units, one for each row). A failing test units means that a given row is not distinct from every other row.\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n         rows_distinct()\n        \n    None\n    None\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom this validation table we see that there are no failing test units. All rows in the table are distinct from one another.\nWe can also use a subset of columns to determine distinctness. Let’s specify the subset using columns col_2 and col_3 for the next validation.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_distinct(columns_subset=[\"col_2\", \"col_3\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n         rows_distinct()\n        \n    ['col_2', 'col_3']\n    None\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The first and second rows are duplicated when considering only the values in columns col_2 and col_3. There’s only one set of duplicates but there are two failing test units since each row is compared to all others."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html",
    "href": "reference/Validate.col_vals_in_set.html",
    "title": "Validate.col_vals_in_set",
    "section": "",
    "text": "Validate.col_vals_in_set(columns, set, pre=None, thresholds=None, active=True)\nValidate whether column values are in a set of values.\nThe col_vals_in_set() validation method checks whether column values in a table are part of a specified set= of values. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#parameters",
    "href": "reference/Validate.col_vals_in_set.html#parameters",
    "title": "Validate.col_vals_in_set",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nset : list[float | int]\n\nA list of values to compare against.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#returns",
    "href": "reference/Validate.col_vals_in_set.html#returns",
    "title": "Validate.col_vals_in_set",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#examples",
    "href": "reference/Validate.col_vals_in_set.html#examples",
    "title": "Validate.col_vals_in_set",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 2, 4, 6, 2, 5],\n        \"b\": [5, 8, 2, 6, 5, 1],\n    }\n)\n\ntbl\n\n\nshape: (6, 2)abi64i64552842662551\n\n\nLet’s validate that values in column a are all in the set of [2, 3, 4, 5, 6]. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_in_set(columns=\"a\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    a\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_in_set(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_in_set(columns=\"b\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    b\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the column b values of 8 and 1, which are not in the set of [2, 3, 4, 5, 6]."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html",
    "href": "reference/Validate.get_sundered_data.html",
    "title": "Validate.get_sundered_data",
    "section": "",
    "text": "Validate.get_sundered_data(type='pass')\nGet the data that passed or failed the validation steps.\nValidation of the data is one thing but, sometimes, you want to use the best part of the input dataset for something else. The get_sundered_data() method works with a Validate object that has been interrogated (i.e., the interrogate() method was used). We can get either the ‘pass’ data piece (rows with no failing test units across all row-based validation functions), or, the ‘fail’ data piece (rows with at least one failing test unit across the same series of validations)."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#details",
    "href": "reference/Validate.get_sundered_data.html#details",
    "title": "Validate.get_sundered_data",
    "section": "Details",
    "text": "Details\nThere are some caveats to sundering. The validation steps considered for this splitting will only involve steps where:\n\nof certain check types, where test units are cells checked row-by-row (e.g., the col_vals_*() methods)\nactive= is not set to False\npre= has not been given an expression for modify the input table\n\nSo long as these conditions are met, the data will be split into two constituent tables: one with the rows that passed all validation steps and another with the rows that failed at least one validation step."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#parameters",
    "href": "reference/Validate.get_sundered_data.html#parameters",
    "title": "Validate.get_sundered_data",
    "section": "Parameters",
    "text": "Parameters\n\ntype :  = 'pass'\n\nThe type of data to return. Options are \"pass\" or \"fail\", where the former returns a table only containing rows where test units always passed validation steps, and the latter returns a table only containing rows had test units that failed in at least one validation step."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#returns",
    "href": "reference/Validate.get_sundered_data.html#returns",
    "title": "Validate.get_sundered_data",
    "section": "Returns",
    "text": "Returns\n\n : FrameT\n\nA table containing the data that passed or failed the validation steps."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#examples",
    "href": "reference/Validate.get_sundered_data.html#examples",
    "title": "Validate.get_sundered_data",
    "section": "Examples",
    "text": "Examples\nLet’s create a Validate object with three validation steps and then interrogate the data.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 6, 9, 7, 3, 2],\n        \"b\": [9, 8, 10, 5, 10, 6],\n        \"c\": [\"c\", \"d\", \"a\", \"b\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:49:35Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_gt()\n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n        \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_in_set()\n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-01-02 04:49:35 UTC&lt; 1 s2025-01-02 04:49:35 UTC\n  \n\n\n\n\n\n\n        \n\n\nFrom the validation table, we can see that the first and second steps each had 4 passing test units. A failing test unit will mark the entire row as failing in the context of the get_sundered_data() method. We can use this method to get the rows of data that passed the during interrogation.\n\nvalidation.get_sundered_data()\n\n\nshape: (2, 3)abci64i64str910\"a\"75\"b\"\n\n\nThe returned DataFrame contains the rows that passed all validation steps. From the six-row input DataFrame, the first two rows and the last two rows had test units that failed validation. Thus the middle two rows are the only ones that passed all validation steps and that’s what we see in the returned DataFrame."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html",
    "href": "reference/Validate.col_vals_null.html",
    "title": "Validate.col_vals_null",
    "section": "",
    "text": "Validate.col_vals_null(columns, pre=None, thresholds=None, active=True)\nValidate whether values in a column are NULL.\nThe col_vals_null() validation method checks whether column values in a table are NULL. This validation will operate over the number of test units that is equal to the number of rows in the table."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#parameters",
    "href": "reference/Validate.col_vals_null.html#parameters",
    "title": "Validate.col_vals_null",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#returns",
    "href": "reference/Validate.col_vals_null.html#returns",
    "title": "Validate.col_vals_null",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#examples",
    "href": "reference/Validate.col_vals_null.html#examples",
    "title": "Validate.col_vals_null",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [None, None, None, None],\n        \"b\": [None, 2, None, 9],\n    }\n).with_columns(pl.col(\"a\").cast(pl.Int64))\n\ntbl\n\n\nshape: (4, 2)abi64i64nullnullnull2nullnullnull9\n\n\nLet’s validate that values in column a are all Null values. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_null(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_null\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_null()\n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_null(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_null(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_null\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_null()\n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the two non-Null values in column b."
  },
  {
    "objectID": "reference/Validate.n_passed.html",
    "href": "reference/Validate.n_passed.html",
    "title": "Validate.n_passed",
    "section": "",
    "text": "Validate.n_passed(i=None, scalar=False)\nProvides a dictionary of the number of test units that passed for each validation step.\nThe n_passed() method provides the number of test units that passed for each validation step. This is the number of test units that passed in the the validation step. It is always some integer value between 0 and the total number of test units.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of passing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the n_failed() method (i.e., n - n_failed)."
  },
  {
    "objectID": "reference/Validate.n_passed.html#parameters",
    "href": "reference/Validate.n_passed.html#parameters",
    "title": "Validate.n_passed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of passing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n_passed.html#returns",
    "href": "reference/Validate.n_passed.html#returns",
    "title": "Validate.n_passed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of passing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n_passed.html#examples",
    "href": "reference/Validate.n_passed.html#examples",
    "title": "Validate.n_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps and, as it turns out, all of them will have failing test units. After interrogation, the n_passed() method is used to determine the number of passing test units for each validation step.\n\nimport polars as pl\nimport pointblank as pb\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12],\n        \"b\": [9, 8, 10, 5, 10],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.n_passed()\n\n{1: 4, 2: 3, 3: 4}\n\n\nThe returned dictionary shows that all validation steps had no passing test units (each value was less than 5, which is the total number of test units for each step).\nIf we wanted to check the number of passing test units for a single validation step, we can provide the step number. Also, we could forego the dictionary and get a scalar value by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.n_passed(i=1)\n\n{1: 4}\n\n\nThe returned value of 4 is the number of passing test units for the first validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html",
    "href": "reference/Validate.col_vals_ne.html",
    "title": "Validate.col_vals_ne",
    "section": "",
    "text": "Validate.col_vals_ne(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nAre column data not equal to a fixed value or data in another column?\nThe col_vals_ne() validation method checks whether column values in a table are not equal to a specified value= (the exact comparison used in this function is col_val != value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#parameters",
    "href": "reference/Validate.col_vals_ne.html#parameters",
    "title": "Validate.col_vals_ne",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str]\n\nA single column or a list of columns to validate. If multiple columns are supplied, there will be a separate validation step generated for each column.\n\nvalue : float | int\n\nThe value to compare against. This can be a single numeric value or a column name given in col().\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#returns",
    "href": "reference/Validate.col_vals_ne.html#returns",
    "title": "Validate.col_vals_ne",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#examples",
    "href": "reference/Validate.col_vals_ne.html#examples",
    "title": "Validate.col_vals_ne",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 5, 5, 5, 5, 5],\n        \"b\": [5, 6, 3, 6, 5, 8],\n    }\n)\n\ntbl\n\n\nshape: (6, 2)abi64i64555653565558\n\n\nLet’s validate that values in column a are not equal to the value of 3. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ne(columns=\"a\", value=3)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_not_equal\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_ne()\n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_ne(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col()) to perform a column-column comparison. For the next example, we’ll use col_vals_ne() to check whether the values in column a aren’t equal to the values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ne(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n        \n\n    col_vals_not_equal\n    \n        \n            \n            \n        \n    \n\n        \n         col_vals_ne()\n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are in rows 0 and 4, where a is 5 and b is 5 in both cases (i.e., they are equal to each other)."
  },
  {
    "objectID": "reference/config.html",
    "href": "reference/config.html",
    "title": "config",
    "section": "",
    "text": "config(report_incl_header=True, report_incl_footer=True)\nConfiguration settings for the pointblank library.\n\n\n\nreport_incl_header : bool = True\n\nThis controls whether the header should be present in the validation table report. The header contains the table name, label information, and might contain global failure threshold levels (if set).\n\nreport_incl_footer : bool = True\n\nShould the footer of the validation table report be displayed? The footer contains the starting and ending times of the interrogation.\n\n\n\n\n\n\n : PointblankConfig\n\nA PointblankConfig object with the specified configuration settings."
  },
  {
    "objectID": "reference/config.html#parameters",
    "href": "reference/config.html#parameters",
    "title": "config",
    "section": "",
    "text": "report_incl_header : bool = True\n\nThis controls whether the header should be present in the validation table report. The header contains the table name, label information, and might contain global failure threshold levels (if set).\n\nreport_incl_footer : bool = True\n\nShould the footer of the validation table report be displayed? The footer contains the starting and ending times of the interrogation."
  },
  {
    "objectID": "reference/config.html#returns",
    "href": "reference/config.html#returns",
    "title": "config",
    "section": "",
    "text": ": PointblankConfig\n\nA PointblankConfig object with the specified configuration settings."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html",
    "href": "reference/Validate.col_schema_match.html",
    "title": "Validate.col_schema_match",
    "section": "",
    "text": "Validate.col_schema_match(\n    schema,\n    complete=True,\n    in_order=True,\n    case_sensitive_colnames=True,\n    case_sensitive_dtypes=True,\n    full_match_dytpes=True,\n    pre=None,\n    thresholds=None,\n    active=True,\n)\nDo columns in the table (and their types) match a predefined schema?\nThe col_schema_match() method works in conjunction with an object generated by the Schema class. That class object is the expectation for the actual schema of the target table. The validation step operates over a single test unit, which is whether the schema matches that of the table (within the constraints enforced by the complete=, and in_order= options)."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#parameters",
    "href": "reference/Validate.col_schema_match.html#parameters",
    "title": "Validate.col_schema_match",
    "section": "Parameters",
    "text": "Parameters\n\nschema : Schema\n\nA Schema object that represents the expected schema of the table. This object is generated by the Schema class.\n\ncomplete : bool = True\n\nShould the schema match be complete? If True, then the target table must have all columns specified in the schema. If False, then the table can have additional columns not in the schema (i.e., the schema is a subset of the target table’s columns).\n\nin_order : bool = True\n\nShould the schema match be in order? If True, then the columns in the schema must appear in the same order as they do in the target table. If False, then the order of columns in the schema and the target table can differ.\n\ncase_sensitive_colnames : bool = True\n\nShould the schema match be case-sensitive with regard to column names? If True, then the column names in the schema and the target table must match exactly. If False, then the column names are compared in a case-insensitive manner.\n\ncase_sensitive_dtypes : bool = True\n\nShould the schema match be case-sensitive with regard to column data types? If True, then the column data types in the schema and the target table must match exactly. If False, then the column data types are compared in a case-insensitive manner.\n\nfull_match_dytpes : bool = True\n\nShould the schema match require a full match of data types? If True, then the column data types in the schema and the target table must match exactly. If False then substring matches are allowed, so a schema data type of Int would match a target table data type of Int64.\n\npre : Callable | None = None\n\nA pre-processing function or lambda to apply to the data table for the validation step.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nFailure threshold levels so that the validation step can react accordingly when exceeding the set levels for different states (warn, stop, and notify). This can be created simply as an integer or float denoting the absolute number or fraction of failing test units for the ‘warn’ level. Otherwise, you can use a tuple of 1-3 values, a dictionary of 1-3 entries, or a Thresholds object.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#returns",
    "href": "reference/Validate.col_schema_match.html#returns",
    "title": "Validate.col_schema_match",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#examples",
    "href": "reference/Validate.col_schema_match.html#examples",
    "title": "Validate.col_schema_match",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three columns (string, integer, and float). The table is shown below:\n\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"apple\", \"banana\", \"cherry\", \"date\"],\n        \"b\": [1, 6, 3, 5],\n        \"c\": [1.1, 2.2, 3.3, 4.4],\n    }\n)\n\ntbl\n\n\nshape: (4, 3)abcstri64f64\"apple\"11.1\"banana\"62.2\"cherry\"33.3\"date\"54.4\n\n\nLet’s validate that the columns in the table match a predefined schema. A schema can be defined using the Schema class.\n\nimport pointblank as pb\n\nschema = pb.Schema(\n    columns=[(\"a\", \"String\"), (\"b\", \"Int64\"), (\"c\", \"Float64\")]\n)\n\nYou can print the schema object to verify that the expected schema is as intended.\n\nschema\n\nSchema(columns=[('a', 'String'), ('b', 'Int64'), ('c', 'Float64')])\n\n\nNow, we’ll use the col_schema_match() method to validate the table against the expected schema object. There is a single test unit for this validation step (whether the schema matches the table or not).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n         col_schema_match()\n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the schema matches the table. The single test unit passed since the table columns and their types match the schema."
  },
  {
    "objectID": "get-started/thresholds.html",
    "href": "get-started/thresholds.html",
    "title": "Thresholds",
    "section": "",
    "text": "This is a work in progress. It’s just an outline for now.\nThresholds enable you to signal failure at different severity levels. In the near future, thresholds will be able to trigger custom actions. For example, when testing a column for NULLs with col_vals_not_null() you might want to warn on any NULLs and stop where there are 10% NULLs in the column.\nimport pointblank as pb\n\nvalidation_1 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_not_null(columns=\"a\", thresholds=(1, 0.1))\n    .interrogate()\n)\n\nvalidation_1\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-01-02|04:50:03Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  S\n  N\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n        \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n         col_vals_not_null()\n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n\n  \n  \n  \n    2025-01-02 04:50:03 UTC&lt; 1 s2025-01-02 04:50:03 UTC\nThe code uses thresholds=(1, 0.1) to set a WARN threshold of 1 and a STOP threshold of 10% failing test units. Notice these pieces in the validation table:\nThe one final threshold, N (NOTIFY), wasn’t set so appears on the validation table as a dash."
  },
  {
    "objectID": "get-started/thresholds.html#using-the-validationthreshold-argument",
    "href": "get-started/thresholds.html#using-the-validationthreshold-argument",
    "title": "Thresholds",
    "section": "Using the Validation(threshold=) argument",
    "text": "Using the Validation(threshold=) argument\nWe can also define thresholds globally. This means that every validation step will re-use the same set of threshold values.\nimport pointblank as pb\n\nvalidation_2 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"), thresholds=(1, 0.1))\n    .col_vals_not_null(columns=\"a\")\n    .col_vals_gt(columns=\"b\", value=2)\n    .interrogate()\n)\n\nvalidation_2\nIn this, both the col_vals_not_null() and col_vals_gt() steps will use the thresholds= value set in the Validate() call. Now, if you want to override these global threshold values for a given validation step, you can always use threshold= argument when calling a validation method."
  },
  {
    "objectID": "get-started/thresholds.html#defining-thresholds",
    "href": "get-started/thresholds.html#defining-thresholds",
    "title": "Thresholds",
    "section": "Defining Thresholds",
    "text": "Defining Thresholds\n\nThreshold shorthands\nThe fastest way to define a threshold is to use a tuple with entries for warn, stop, and nofify levels.\n# [WARN, STOP, NOTIFY]\nthreshold = (1, 2, 3)\n\nValidate(data=..., threshold=threshold)\nNote that a shorter tuple or even single values are also allowed:\n\n(1, 2): warn state at 1 failing test unit, stop state at 2 failing test units\n1 or (1, ): warn state at 1 failing test unit\n\n\n\nThreshold cutoff values\nThreshold values can be specified in two ways:\n\npercentage: a decimal value like 0.1 to mean 10% test units failed\nnumber: a fixed number of test units failed\n\nThreshold cutoffs are inclusive so any value of failing test units greater than or equal to the cutoff will result in triggering the threshold. So if a threshold is defined with a cutoff value of 5, then 5 failing test units will result in threshold.\n\n\nThe Threshold class"
  },
  {
    "objectID": "get-started/thresholds.html#triggering-actions",
    "href": "get-started/thresholds.html#triggering-actions",
    "title": "Thresholds",
    "section": "Triggering Actions",
    "text": "Triggering Actions\nThis is not currently implemented."
  },
  {
    "objectID": "get-started/thresholds.html#use-case-stopping-on-any-failures",
    "href": "get-started/thresholds.html#use-case-stopping-on-any-failures",
    "title": "Thresholds",
    "section": "Use Case: Stopping on any Failures",
    "text": "Use Case: Stopping on any Failures"
  },
  {
    "objectID": "get-started/thresholds.html#use-case-global-tolerance-bands",
    "href": "get-started/thresholds.html#use-case-global-tolerance-bands",
    "title": "Thresholds",
    "section": "Use Case: Global tolerance bands",
    "text": "Use Case: Global tolerance bands"
  },
  {
    "objectID": "get-started/thresholds.html#use-case-schema-correctness-after-table-joins",
    "href": "get-started/thresholds.html#use-case-schema-correctness-after-table-joins",
    "title": "Thresholds",
    "section": "Use Case: Schema Correctness After Table Joins",
    "text": "Use Case: Schema Correctness After Table Joins"
  }
]